library(tm)
library(RWeka) ##Got it!
library(qdap)
library(stringi)
install.packages("stringi")
install.packages("stringi")
library(ggplot2)
library(ggplot)
library(tm)
library(RWeka) ##Got it!
library(qdap)
library(stringi)
library(ggplot2)
library(ngram)
test<-file.path("C:/Users/jdlevy/Documents/datasciencecoursera/10 Capstone/final", "shortfile")
##Create corpus
corpus<-Corpus(DirSource(test))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, PlainTextDocument)
dtm<-DocumentTermMatrix(corpus)
tdm<-TermDocumentMatrix(corpus)
dtms<-removeSparseTerms(dtm, 0.1)
freq3 <- sort(colSums(as.matrix(dtms)), decreasing=TRUE)
lots<-findFreqTerms(dtm, lowfreq=1000)   #Words appearing 1000 or more times
wf <- data.frame(word=names(freq3), freq=freq3)
single<-ngram(corpus, n=1)
single<-ngram(test, n=2)
single
ngram(corpus, n=1)
library(tm)
library(RWeka) ##Got it!
library(qdap)
library(stringi)
library(ggplot2)
library(ngram)
test<-file.path("C:/Users/jdlevy/Documents/datasciencecoursera/10 Capstone/final", "shortfile")
##Create corpus
corpus<-Corpus(DirSource(test))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, PlainTextDocument)
dtm<-DocumentTermMatrix(corpus)
tdm<-TermDocumentMatrix(corpus)
freq<-colSums(as.matrix(dtm))
length(freq)
ord<-order(freq)
##Remove infrequent terms
dtms<-removeSparseTerms(dtm, 0.1)
test<-file.path("C:/Users/jdlevy/Documents/datasciencecoursera/10 Capstone/final", "shortfile")
##Create corpus
corpus<-Corpus(DirSource(test))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, PlainTextDocument)
dtm<-DocumentTermMatrix(corpus)
tdm<-TermDocumentMatrix(corpus)
freq<-colSums(as.matrix(dtm))
length(freq)
ord<-order(freq)
##Remove infrequent terms
dtms<-removeSparseTerms(dtm, 0.1)
freq3 <- sort(colSums(as.matrix(dtms)), decreasing=TRUE)
lots<-findFreqTerms(dtm, lowfreq=1000)   #Words appearing 1000 or more times
wf <- data.frame(word=names(freq3), freq=freq3)
Onegram <- NGramTokenizer(corpus, Weka_control(min = 1, max = 1))
Bigram <- NGramTokenizer(corpus, Weka_control(min = 2, max = 2))
Trigram <- NGramTokenizer(corpus, Weka_control(min = 3, max = 3))
Quadgram<- NGramTokenizer(corpus, Weka_control(min=4, max=4))
##Modify to data frames
onet <- data.frame(table(Onegram))
twot <- data.frame(table(Bigram))
threet <- data.frame(table(Trigram))
quadt<- data.frame(table(Quadgram))
onesort<-onet[order(onet$Freq,decreasing=TRUE),]
twosort<-twot[order(twot$Freq,decreasing=TRUE),]
threesort<-threet[order(threet$Freq,decreasing=TRUE),]
quadsort<-quadt[order(quadt$Freq, decreasing=TRUE),]
##Sorted data frames as just top 20 phrases
ones <- onesort[1:20,]
colnames(ones) <- c("Word","Frequency")
twos <- twosort[1:20,]
colnames(twos) <- c("Word","Frequency")
threes <- threesort[1:20,]
colnames(threes) <- c("Word","Frequency")
quads <- quadsort[1:20,]
colnames(quads) <- c("Word","Frequency")
n1<-ggplot(ones, aes(x=Word,y=Frequency)) + geom_bar(stat="Identity", fill="Blue") +geom_text(aes(label=Frequency)) + theme(axis.text.x = element_text(angle = 45, hjust = 1))
n2<-ggplot(twos, aes(x=Word,y=Frequency)) + geom_bar(stat="Identity", fill="Blue") +geom_text(aes(label=Frequency)) + theme(axis.text.x = element_text(angle = 45, hjust = 1))
n3<-ggplot(threes, aes(x=Word,y=Frequency)) + geom_bar(stat="Identity", fill="Blue") +geom_text(aes(label=Frequency)) + theme(axis.text.x = element_text(angle = 45, hjust = 1))
n4<-ggplot(quads, aes(x=Word,y=Frequency)) + geom_bar(stat="Identity", fill="Blue") +geom_text(aes(label=Frequency)) + theme(axis.text.x = element_text(angle = 45, hjust = 1))
library(caret)
tdf<-twosort[1:2300,]
df3<-threesort[1:2300,]
findAssocs(dtms, "the", corlimit=0.98)
findAssocs(dtms, "the", corlimit=1.0)
findAssocs(dtms, "the", corlimit=0.999)
ones
twos
findAssocs(dtms, "of the", corlimit=0.999)
findAssocs(twos, "of the", corlimit=0.999)
class(dtms)
class(twos)
twom<-as.matrix(twos)
twom
findAssocs(twom, "of the", corlimit=0.999)
str(dtms)
summary(dtms)
library(tm)
library(RWeka) ##Got it!
library(qdap)
library(stringi)
library(ggplot2)
library(ngram)
test<-file.path("C:/Users/jdlevy/Documents/datasciencecoursera/10 Capstone/final", "shortfile")
##Create corpus
corpus<-Corpus(DirSource(test))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, PlainTextDocument)
dtm<-DocumentTermMatrix(corpus)
tdm<-TermDocumentMatrix(corpus)
dtms<-removeSparseTerms(dtm, 0.1)
freq3 <- sort(colSums(as.matrix(dtms)), decreasing=TRUE)
lots<-findFreqTerms(dtm, lowfreq=1000)   #Words appearing 1000 or more times
wf <- data.frame(word=names(freq3), freq=freq3)
p <- ggplot(subset(wf, freq>1000), aes(word, freq))
p <- p + geom_bar(stat="identity")
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))
p
unique(freq3)
unique(freq3$word)
head(freq3)
freq3
wf
head(wf)
Onegram <- NGramTokenizer(corpus, Weka_control(min = 1, max = 1))
Bigram <- NGramTokenizer(corpus, Weka_control(min = 2, max = 2))
Trigram <- NGramTokenizer(corpus, Weka_control(min = 3, max = 3))
Quadgram<- NGramTokenizer(corpus, Weka_control(min=4, max=4))
onet <- data.frame(table(Onegram))
twot <- data.frame(table(Bigram))
threet <- data.frame(table(Trigram))
quadt<- data.frame(table(Quadgram))
##Sort data frames
onesort<-onet[order(onet$Freq,decreasing=TRUE),]
twosort<-twot[order(twot$Freq,decreasing=TRUE),]
threesort<-threet[order(threet$Freq,decreasing=TRUE),]
quadsort<-quadt[order(quadt$Freq, decreasing=TRUE),]
ones <- onesort[1:20,]
colnames(ones) <- c("Word","Frequency")
twos <- twosort[1:20,]
colnames(twos) <- c("Word","Frequency")
threes <- threesort[1:20,]
colnames(threes) <- c("Word","Frequency")
quads <- quadsort[1:20,]
colnames(quads) <- c("Word","Frequency")
##Plot top 20 phrases for each n-gram
library(ggplot2)
n1<-ggplot(ones, aes(x=Word,y=Frequency)) + geom_bar(stat="Identity", fill="Blue") +geom_text(aes(label=Frequency)) + theme(axis.text.x = element_text(angle = 45, hjust = 1))
n2<-ggplot(twos, aes(x=Word,y=Frequency)) + geom_bar(stat="Identity", fill="Blue") +geom_text(aes(label=Frequency)) + theme(axis.text.x = element_text(angle = 45, hjust = 1))
n3<-ggplot(threes, aes(x=Word,y=Frequency)) + geom_bar(stat="Identity", fill="Blue") +geom_text(aes(label=Frequency)) + theme(axis.text.x = element_text(angle = 45, hjust = 1))
n4<-ggplot(quads, aes(x=Word,y=Frequency)) + geom_bar(stat="Identity", fill="Blue") +geom_text(aes(label=Frequency)) + theme(axis.text.x = element_text(angle = 45, hjust = 1))
n1
n2
n3
n4
ones
twos
threes
fours
quads
ofthe<-grep("of the", threesort$Trigram, value=TRUE)
ofthe
testes<-grep(twosort$Bigram, threesort$Trigram, value=TRUE)
testes
?lapply
trying<-lapply(threesort, function(x) x=grep(twosort$Bigram, threesort$Trigram, value=TRUE))
trying
trying<-lapply(threesort, function(x) x=grep(twosort$Bigram, threesort$Trigram, value=TRUE))
str(testes)
summary(testes)
testes2<-grep("of the|in the|to the|on the|for the", threesort$Trigram, value=TRUE)
str(testes2)
summary(testes2)
grepFun <- function(rw){
grepl(twosort$Bigram[1],threesort$Trigram,fixed=TRUE)
}
xx <- apply(greptest,1,grepFun)
greptest$output[xx] <- "STRING_FOUND"
grepFun <- function(rw){
grepl(twosort$Bigram[1],threesort$Trigram,fixed=TRUE)
}
xx <- apply(threesort,1,grepFun)
threesort$output[xx] <- "STRING_FOUND"
class(ones)
class(onesort)
tdf<-twosort[1:2300,]
df3<-threesort[1:2300,]
head(tdf)
grepFun <- function(rw){
grepl(tdf$Bigram[1],df3$Trigram,fixed=TRUE)
}
xx <- apply(df3,1,grepFun)
df3$output[xx] <- "STRING_FOUND"
xx
osum<-sum(onesort$Freq)
osum
head(onesort)
bisum<-sum(twosort$Freq)
trisum<-sum(threesort$Freq)
quadsum<-sum(quadsort$Freq)
bisum
trisum
quadsum
?p
?prob
?P
ones
21774/osum
n1
n2
n
n3
threes
find3<-grep("one of the|a lot of|going to be|to be a|it was a", quadsort$Quadgram, value=TRUE)
str(find3)
summary(find3)
find2<-grep("of the|in the|to the|on the|for the", threesort$Trigram, value=TRUE)
summary(find2)
ones
find1<-grep("the|to|and|a|of", twosort$Bigram, value=TRUE)
summary(find1)
combo<-cbind(ones, twos, threes)
combo
str(combo)
ones <- onesort[1:20,]
colnames(ones) <- c("Word","Frequency")
twos <- twosort[1:20,]
colnames(twos) <- c("Word2","Frequency2")
threes <- threesort[1:20,]
colnames(threes) <- c("Word3","Frequency3")
quads <- quadsort[1:20,]
colnames(quads) <- c("Word4","Frequency4")
ones <- onesort[1:20,]
colnames(ones) <- c("Word","Frequency")
twos <- twosort[1:20,]
colnames(twos) <- c("Word","Frequency")
threes <- threesort[1:20,]
colnames(threes) <- c("Word","Frequency")
quads <- quadsort[1:20,]
colnames(quads) <- c("Word","Frequency")
combo<-rbind(ones, twos, threes, quads)
str(combo)
combo
onesx <- onesort[1:20,]
colnames(ones) <- c("Word","Frequency")
twosx <- twosort[1:20,]
colnames(twos) <- c("Word2","Frequency2")
threesx <- threesort[1:20,]
colnames(threes) <- c("Word3","Frequency3")
quadsx <- quadsort[1:20,]
colnames(quads) <- c("Word4","Frequency4")
combo2<-cbind(onesx, twosx, threesx, quadsx)
combo2
ones <- onesort[1:20,]
colnames(ones) <- c("Word","Frequency")
twos <- twosort[1:20,]
colnames(twos) <- c("Word","Frequency")
threes <- threesort[1:20,]
colnames(threes) <- c("Word","Frequency")
quads <- quadsort[1:20,]
colnames(quads) <- c("Word","Frequency")
onesx <- onesort[1:20,]
colnames(onesx) <- c("Word","Frequency")
twosx <- twosort[1:20,]
colnames(twosx) <- c("Word2","Frequency2")
threesx <- threesort[1:20,]
colnames(threesx) <- c("Word3","Frequency3")
quadsx <- quadsort[1:20,]
colnames(quadsx) <- c("Word4","Frequency4")
combo2<-cbind(onesx, twosx, threesx, quadsx)
combo2
class(combo2$Word)
class(combo2$Word2)
class(combo2)
trym<-train(combo2$Word2~combo2$Word3)
library(caret)
trym<-train(combo2$Word2~combo2$Word3)
trym<-train(combo2$Word3~combo2$Word4)
trym<-lm(combo2$Word2~combo2$Word3)
plot(trym)
trym
summary(trym)
find1
head(find1)
head(twosort)
findone<-grep("the", twosort$Bigram, value=TRUE)
findone
head(findone)
head(twosort)
library(cluster)
d<-dist(t(dtms), method="euclidian")
fit<-hclust(d=d, method="ward")
plot(fit, hang=-1)
fit<-hclust(d=d, method="ward")
kfit<-kmeans(d,2)
combo
library(tm)
library(RWeka) ##Got it!
library(qdap)
library(stringi)
library(ggplot2)
library(ngram)
test<-file.path("C:/Users/jdlevy/Documents/datasciencecoursera/10 Capstone/final", "shortfile")
##Create corpus
corpus<-Corpus(DirSource(test))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, PlainTextDocument)
dtm<-DocumentTermMatrix(corpus)
tdm<-TermDocumentMatrix(corpus)
dtms<-removeSparseTerms(dtm, 0.1)
Onegram <- NGramTokenizer(corpus, Weka_control(min = 1, max = 1))
Bigram <- NGramTokenizer(corpus, Weka_control(min = 2, max = 2))
Trigram <- NGramTokenizer(corpus, Weka_control(min = 3, max = 3))
Quadgram<- NGramTokenizer(corpus, Weka_control(min=4, max=4))
onet <- data.frame(table(Onegram))
twot <- data.frame(table(Bigram))
threet <- data.frame(table(Trigram))
quadt<- data.frame(table(Quadgram))
onesort<-onet[order(onet$Freq,decreasing=TRUE),]
twosort<-twot[order(twot$Freq,decreasing=TRUE),]
threesort<-threet[order(threet$Freq,decreasing=TRUE),]
quadsort<-quadt[order(quadt$Freq, decreasing=TRUE),]
head(onesort)
tail(onesort)
head(twosort)
ones <- onesort[1:20,]
colnames(ones) <- c("Word","Frequency")
twos <- twosort[1:20,]
colnames(twos) <- c("Word","Frequency")
threes <- threesort[1:20,]
colnames(threes) <- c("Word","Frequency")
quads <- quadsort[1:20,]
colnames(quads) <- c("Word","Frequency")
combo<-rbind(ones, twos, threes, quads)
head(combo)
tail(combo)
class(combo)
trying<-grep("of the", combo$Word)
trying
combo[21,]
combo[41,]
finding<-grep("the", combo$Word, value=TRUE)
finding
finding<-grep("of the", combo$Word, value=TRUE)
finding
grep("case of", combo$Word)\
grep("case of", combo$Word)
combine<-rbind(onesort, twosort, threesort)
colnames(onesort) <- c("Word","Frequency")
colnames(twosort) <- c("Word","Frequency")
colnames(threesort) <- c("Word","Frequency")
combine<-rbind(onesort, twosort, threesort)
grep("case of", combine$Word)
combine[40249,]
combine[281714,]
combine[283035,]
combine[290079,]
combine[563714,]
grep("mean the", combine$Word)
combine[49985,]
combine[185908,]
combine[185909,]
combine[389744,]
combine[389745,]
grep("would mean the", combine$Word)
combine[661785,]
colnames(quadsort) <- c("Word","Frequency")
combine<-rbind(onesort, twosort, threesort, quadosort)
combine<-rbind(onesort, twosort, threesort, quadsort)
grep("a case of", combine$Word)
combine[283035,]
combine[1028718,]
combine[876700,]
combine[825587,]
combine[736809,]
combine[674322,]
combine[674323,]
combine[674321,]
combine[67432,]
combine[67430,]
combine[674320,]
combine[736809|825587,]
combine[736809:825587,]
combine[736809 &or& 825587,]
combine[736809 & 825587,]
grep("would mean the", combine$Word)
combine[661785]
combine[661785]
combine[661785,]
combine[861260,]
combine[1085520,]
grep("make me the", combine$Word, value=TRUE)
grep("make me the", combine$Word, value=T)
grep("make me the", combine$Word)
grep("struggling but the", combine$Word)
grep("but the", combine$Word)
grep("but the", combine$Word, value=TRUE)
grep("but the$", combine$Word)
grep("would mean the$", combine$Word)
grep("would mean the", combine$Word)
combine[1085520,]
grep("^would mean the", combine$Word)
grep("^make me the", combine$Word)
grep("^a case of", combine$Word)
combine[283035,]
combine[674320],]
combine[674320,]
combine[674321,]
combine[674322,]
combine[674323,]
grep("happiest$", quadsort$Word)
quadosort[261633,]
quadsort[261633,]
quadsort[342790,]
grep("^struggling but the", quadsort$Word)
grep("struggling but the", quadsort$Word)
grep("^but the", threesort$Word)
grep("^but the", threesort$Word, value=T)
grep("but the players", threesort$Word)
grep("but the referees", threesort$Word)
grep("but the crowd", threesort$Word)
grep("but the defense", threesort$Word)
grep("^date at the", combine$Word)
grep("^date at the", quadsort$Word)
grep("date at the", quadsort$Word)
quadsort[76242,]
grep("date at the", quadsort$Word, value=TRUE)
grep("beach$", combine$Word)
grep("beach$", combine$Word, value=TRUE)
grep("romantic", combine$Word, value=TRUE)
grep("romantic" & "beach", combine$Word)
grep("romantic|date", combine$Word)
grep("romantic|date|at", combine$Word)
grep("romantic\|date\|at", combine$Word)
grep("romantic*date", combine$Word)
grep("romantic+date", combine$Word)
grep("romantic+.+date", combine$Word)
grep("romantic date", combine$Word)
grep("date at the", combine$Word)
grep("date at the", combine$Word, value=TRUE)
grep("be on my", combine$Word, value=TRUE)
grep("on my", combine$Word, value=TRUE)
grep("^on my", combine$Word, value=TRUE)
grep("^in quite some", combine$Word, value=TRUE)
grep("in quite some", combine$Word, value=TRUE)
grep("quite some", combine$Word, value=TRUE)
grep("with his little", combine$Word, value=TRUE)
grep("his little", combine$Word, value=TRUE)
grep("during the", combine$Word, value=TRUE)
grep("during the bad", combine$Word, value=TRUE)
grep("during the worse", combine$Word, value=TRUE)
grep("during the hard", combine$Word, value=TRUE)
grep("the hard", combine$Word)
grep("the bad", combine$Word)
combine[43371,]
grep("the sad", combine$Word)
combine[1,]
grep("the worse", combine$Word)
grep("little fingers", combine$Word)
grep("little toes", combine$Word)
grep("you must be", combine$Word)
grep("you must be", combine$Word, value=TRUE)
grep("be insane", combine$Word)
grep("be insensitive", combine$Word)
grep("be callous", combine$Word)
grep("be asleep", combine$Word)
rm(list = ls()) #clean environment
getwd()
setwd("C:/Users/jdlevy/Documents/datasciencecoursera/10 Capstone/final")
shinyapps::setAccountInfo(name='joebookslevy', token='DD36C840B56DBE285D45E901AC476E35', secret='XOqp1fAcE/LWAtWVX6fvrBhtiOkqOsfy4Jv6hq+Y')
shiny::runApp()
setwd("C:/Users/jdlevy/Documents/datasciencecoursera/10 Capstone/final")
setwd("~/datasciencecoursera/10 Capstone/final")
setwd("~/datasciencecoursera/10 Capstone/final")
setwd("C:/Users/jdlevy/Documents/datasciencecoursera/10 Capstone/final")
file.list()
ls()
shiny::runApp()
shinyapps::setAccountInfo(name='joebookslevy', token='D4CAA4C1772A8C3EB0A2FB783A98C18D', secret='Au30ERtUXPT/ECuJOOSdCtccqsiSwVLOGRDe1MFt')
library(shinyapps)
deployApp()
install.packages("httr")
